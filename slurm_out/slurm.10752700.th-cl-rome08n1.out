Rank=0: Total number of GPUs: 1, devices: [CpuDevice(id=0)]
Rank=0: Local number of GPUs: 1, devices: [CpuDevice(id=0)]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [01:18<?, ?it/s, Energy=-1.42-0.00j ± 0.29 [σ²=7.4e+01, R̂=1.225]]100%|██████████| 1/1 [00:00<00:00, 24.21it/s, Energy=-1.42-0.00j ± 0.29 [σ²=7.4e+01, R̂=1.225]]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [01:16<?, ?it/s, Energy=-2.19-0.00j ± 0.30 [σ²=8.8e+01, R̂=1.225]]100%|██████████| 1/1 [00:00<00:00, 1659.80it/s, Energy=-2.19-0.00j ± 0.30 [σ²=8.8e+01, R̂=1.225]]
/scratch/f/F.Conoscenti/Thesis_QSL/Elaborate/Plotting/Sign_vs_iteration.py:352: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout(rect=[0, 0, 0.80, 1])  # leave room on the right for our insets
/scratch/f/F.Conoscenti/Thesis_QSL/HFDS_Heisenberg/run_spin.py:244: UserWarning: n_samples=256 (256 per JAX device) does not divide n_chains=512, increased to 512 (512 per JAX device)
  vstate.n_samples = 256
