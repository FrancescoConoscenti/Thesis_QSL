Rank=0: Total number of GPUs: 1, devices: [CpuDevice(id=0)]
Rank=0: Local number of GPUs: 1, devices: [CpuDevice(id=0)]
  0%|          | 0/1 [00:00<?, ?it/s]2025-11-11 18:00:05.678216: E external/xla/xla/service/slow_operation_alarm.cc:73] 
********************************
[Compiling module jit_srt_onthefly] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2025-11-11 18:04:31.330828: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 6m25.655676463s

********************************
[Compiling module jit_srt_onthefly] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
  0%|          | 0/1 [09:22<?, ?it/s, Energy=-5.81+0.00j ± 0.27 [σ²=8.0e+01, R̂=1.225]]100%|██████████| 1/1 [00:06<00:00,  6.05s/it, Energy=-5.81+0.00j ± 0.27 [σ²=8.0e+01, R̂=1.225]]100%|██████████| 1/1 [00:06<00:00,  6.05s/it, Energy=-5.81+0.00j ± 0.27 [σ²=8.0e+01, R̂=1.225]]
/scratch/f/F.Conoscenti/Thesis_QSL/Elaborate/Plotting/Sign_vs_iteration.py:352: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout(rect=[0, 0, 0.80, 1])  # leave room on the right for our insets
/scratch/f/F.Conoscenti/Thesis_QSL/HFDS_Heisenberg/run_spin.py:244: UserWarning: n_samples=256 (256 per JAX device) does not divide n_chains=512, increased to 512 (512 per JAX device)
  vstate.n_samples = 256
slurmstepd: error: Detected 1 oom_kill event in StepId=10753259.0. Some of the step tasks have been OOM Killed.
srun: error: th-cl-naples19: task 0: Out Of Memory
srun: Terminating StepId=10753259.0
