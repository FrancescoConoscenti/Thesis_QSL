Rank=0: Total number of GPUs: 1, devices: [CpuDevice(id=0)]
Rank=0: Local number of GPUs: 1, devices: [CpuDevice(id=0)]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [01:41<?, ?it/s, Energy=-5.24+0.00j ± 0.30 [σ²=9.7e+01, R̂=1.225]]100%|██████████| 1/1 [00:00<00:00, 21.22it/s, Energy=-5.24+0.00j ± 0.30 [σ²=9.7e+01, R̂=1.225]]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [01:44<?, ?it/s, Energy=-6.12-0.00j ± 0.32 [σ²=1.0e+02, R̂=1.225]]100%|██████████| 1/1 [00:00<00:00, 1321.04it/s, Energy=-6.12-0.00j ± 0.32 [σ²=1.0e+02, R̂=1.225]]
/scratch/f/F.Conoscenti/Thesis_QSL/Elaborate/Plotting/Sign_vs_iteration.py:352: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout(rect=[0, 0, 0.80, 1])  # leave room on the right for our insets
/scratch/f/F.Conoscenti/Thesis_QSL/HFDS_Heisenberg/run_spin.py:244: UserWarning: n_samples=256 (256 per JAX device) does not divide n_chains=512, increased to 512 (512 per JAX device)
  vstate.n_samples = 256
