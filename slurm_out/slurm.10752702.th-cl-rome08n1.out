Rank=0: Total number of GPUs: 1, devices: [CpuDevice(id=0)]
Rank=0: Local number of GPUs: 1, devices: [CpuDevice(id=0)]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [01:20<?, ?it/s, Energy=-2.64-0.00j ± 0.32 [σ²=9.1e+01, R̂=1.225]]100%|██████████| 1/1 [00:00<00:00, 22.97it/s, Energy=-2.64-0.00j ± 0.32 [σ²=9.1e+01, R̂=1.225]]
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [01:19<?, ?it/s, Energy=-3.44-0.00j ± 0.31 [σ²=9.3e+01, R̂=1.225]]100%|██████████| 1/1 [00:00<00:00, 1732.47it/s, Energy=-3.44-0.00j ± 0.31 [σ²=9.3e+01, R̂=1.225]]
/scratch/f/F.Conoscenti/Thesis_QSL/Elaborate/Plotting/Sign_vs_iteration.py:352: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout(rect=[0, 0, 0.80, 1])  # leave room on the right for our insets
/scratch/f/F.Conoscenti/Thesis_QSL/HFDS_Heisenberg/run_spin.py:244: UserWarning: n_samples=256 (256 per JAX device) does not divide n_chains=512, increased to 512 (512 per JAX device)
  vstate.n_samples = 256
